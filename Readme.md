# Project : Implement Time2vec on time series data and fetch top 3 correlations 

## ðŸ”¹ 1. Synthetic Dataset Creation

- Dataset consists of **1000 rows** and **10 metrics**.
- Three metrics are intentionally correlated by fitting them to a shared base signal:
  - `cpu_usage`
  - `memory_usage`
  - `disk_io`
- Remaining metrics are generated using Gaussian noise:
  - `network_in`
  - `network_out`
  - `db_queries`
  - `db_latency`
  - `app_errors`
  - `response_time`
  - `active_users`

    Dataset saved as `data/metrics.csv`  
    Data generation logic is in `create_data.py`

---
## ðŸ”¹ 2. Time2Vec Model

- Time2Vec implementation inspired by: [Time2Vec-PyTorch](https://github.com/ojus1/Time2Vec-PyTorch)
- Based on the formulation in the [original paper](https://arxiv.org/pdf/1907.05321.pdf):
t2v(Ï„)[i] = Ï‰áµ¢Ï„ + Ï•áµ¢, if i = 0
F(Ï‰áµ¢Ï„ + Ï•áµ¢), if 1 â‰¤ i â‰¤ k

## ðŸ”¹ 3. Inference & Embedding

- Normalized time values are passed to the Time2Vec model.
- Outputs a time embedding vector for each timestamp.
- These embeddings are used to assess similarity between time series.

---
## similarity search :
- Pearsons correlation is used to find similar vectors 

## alternatives : 
- we can use the faiss similarity search as well as cosine similarity.

## project structure 
## ðŸ“‚ Project Structure

- `Data/`  
  &nbsp;&nbsp;&nbsp;&nbsp;â”œâ”€â”€ `create_data.py` â€“ Script to generate synthetic data  
  &nbsp;&nbsp;&nbsp;&nbsp;â””â”€â”€ `metrics.csv` â€“ Generated synthetic multivariate time-series dataset

- `Readme.md` â€“ Project documentation

- `Time_vector_correlation.ipynb` â€“ Main notebook implementing Time2Vec and correlation analysis
